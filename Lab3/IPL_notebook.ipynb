{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "063ced0c-5476-42f0-b1fb-6eb564de3f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, mean, count\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, ClusteringEvaluator, RegressionEvaluator\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.sql.functions import mean, count, when\n",
    "from pyspark.ml.feature import VectorAssembler, OneHotEncoder, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d8b91b2-7ea1-425c-b255-f09fb2bc6804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/25 05:50:37 WARN Utils: Your hostname, Molphie resolves to a loopback address: 127.0.1.1; using 192.168.6.223 instead (on interface enp4s0)\n",
      "25/06/25 05:50:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/25 05:50:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/25 05:50:38 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"IPL_ML_Experiments\").getOrCreate()\n",
    "df = spark.read.csv(\"deliveries.csv\", header=True, inferSchema=True)\n",
    "df = df.na.drop(subset=[\"batter\", \"bowler\", \"over\", \"ball\", \"total_runs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d75104-2ea1-4f41-a3ee-f15a781f5343",
   "metadata": {},
   "source": [
    "# Классификация\n",
    "Цель: Предсказать, будет ли удар на 4 или 6 (boundary или нет)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "039e43e1-fb04-41c7-870d-de965a31ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cls = df.withColumn(\"is_boundary\", when((col(\"batsman_runs\") == 4) | (col(\"batsman_runs\") == 6), 1).otherwise(0))\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=\"batter\", outputCol=\"batter_idx\"),\n",
    "    StringIndexer(inputCol=\"bowler\", outputCol=\"bowler_idx\"),\n",
    "    StringIndexer(inputCol=\"batting_team\", outputCol=\"batting_team_idx\"),\n",
    "]\n",
    "\n",
    "features_cls = [\"over\", \"ball\", \"batter_idx\", \"bowler_idx\", \"batting_team_idx\"]\n",
    "assembler_cls = VectorAssembler(inputCols=features_cls, outputCol=\"features\")\n",
    "rf = RandomForestClassifier(\n",
    "    labelCol=\"is_boundary\",\n",
    "    featuresCol=\"features\",\n",
    "    seed=42,\n",
    "    numTrees=30,\n",
    "    maxDepth=5,\n",
    "    maxBins=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dd1e0ba-6558-4de5-8b1f-08e3b9644446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/25 05:50:48 WARN DAGScheduler: Broadcasting large task binary with size 1299.0 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      "ROC AUC: 0.576\n",
      "Accuracy: 0.836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_cls = Pipeline(stages=indexers + [assembler_cls, rf])\n",
    "model_cls = pipeline_cls.fit(df_cls)\n",
    "pred_cls = model_cls.transform(df_cls)\n",
    "evaluator_cls = BinaryClassificationEvaluator(labelCol=\"is_boundary\", metricName=\"areaUnderROC\")\n",
    "roc_auc = evaluator_cls.evaluate(pred_cls)\n",
    "acc = pred_cls.filter(col(\"is_boundary\") == col(\"prediction\")).count() / df_cls.count()\n",
    "print(f\"RandomForest\\nROC AUC: {roc_auc:.3f}\\nAccuracy: {acc:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2152c891-5daf-4ec2-aed1-0d029129c0a5",
   "metadata": {},
   "source": [
    "# Кластеризация баттеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48d67a35-bb05-4bcb-a4e9-8c30e3842d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans\n",
      "Silhouette: 0.644\n",
      "WSSSE: 1.70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agg = (\n",
    "    df.groupBy(\"batter\")\n",
    "    .agg(\n",
    "        mean(\"batsman_runs\").alias(\"avg_runs\"),\n",
    "        (count(when((col(\"batsman_runs\")==4) | (col(\"batsman_runs\")==6), True)) / count(\"*\")).alias(\"boundary_pct\"),\n",
    "        count(\"*\").alias(\"balls_faced\"),\n",
    "    )\n",
    "    .filter(col(\"balls_faced\") > 100)\n",
    ")\n",
    "vec_assembler = VectorAssembler(inputCols=[\"avg_runs\", \"boundary_pct\"], outputCol=\"features\")\n",
    "kmeans = KMeans(k=4, seed=1)\n",
    "pipeline_clus = Pipeline(stages=[vec_assembler, kmeans])\n",
    "model_clus = pipeline_clus.fit(agg)\n",
    "pred_clus = model_clus.transform(agg)\n",
    "evaluator_clus = ClusteringEvaluator()\n",
    "silhouette = evaluator_clus.evaluate(pred_clus)\n",
    "wssse = model_clus.stages[-1].summary.trainingCost\n",
    "print(f\"KMeans\\nSilhouette: {silhouette:.3f}\\nWSSSE: {wssse:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c56334f-ee19-4a42-a345-9579348e84ac",
   "metadata": {},
   "source": [
    "# Регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59a16df9-9c41-4b3d-bfd8-465088bea09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/25 05:50:55 WARN Instrumentation: [8db144b4] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"total_runs\")\n",
    "pipeline_reg = Pipeline(stages=indexers + [assembler_cls, lr])\n",
    "model_reg = pipeline_reg.fit(df)\n",
    "pred_reg = model_reg.transform(df)\n",
    "evaluator_reg = RegressionEvaluator(labelCol=\"total_runs\", predictionCol=\"prediction\", metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11bdef83-593f-41c7-9537-442a80287520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "RMSE: 1.617\n",
      "R2: 0.012\n"
     ]
    }
   ],
   "source": [
    "rmse = evaluator_reg.evaluate(pred_reg)\n",
    "r2 = RegressionEvaluator(labelCol=\"total_runs\", predictionCol=\"prediction\", metricName=\"r2\").evaluate(pred_reg)\n",
    "print(f\"LinearRegression\\nRMSE: {rmse:.3f}\\nR2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6ac2ef0-53ac-41d3-ad40-2e33fa37fcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/25 05:51:09 WARN DAGScheduler: Broadcasting large task binary with size 1388.0 KiB\n",
      "25/06/25 05:51:11 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "25/06/25 05:51:14 WARN DAGScheduler: Broadcasting large task binary with size 4.8 MiB\n",
      "25/06/25 05:51:17 WARN DAGScheduler: Broadcasting large task binary with size 1144.2 KiB\n",
      "WARNING: An illegal reflective access operation has occurred                    \n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/opt/spark/jars/spark-core_2.12-3.4.4.jar) to field java.nio.charset.Charset.name\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "[Stage 198:========>                                                (1 + 6) / 7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor:\n",
      "RMSE: 1.596\n",
      "R2: 0.037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Агрегаты по баттеру и боулеру\n",
    "batter_stats = df.groupBy(\"batter\").agg(\n",
    "    mean(\"batsman_runs\").alias(\"batter_avg\"),\n",
    "    (count(when((col(\"batsman_runs\")==4) | (col(\"batsman_runs\")==6), True)) / count(\"*\")).alias(\"batter_boundary_pct\"),\n",
    "    count(\"*\").alias(\"batter_balls\")\n",
    ")\n",
    "\n",
    "bowler_stats = df.groupBy(\"bowler\").agg(\n",
    "    mean(\"batsman_runs\").alias(\"bowler_avg\"),\n",
    "    (count(when((col(\"batsman_runs\")==4) | (col(\"batsman_runs\")==6), True)) / count(\"*\")).alias(\"bowler_boundary_pct\"),\n",
    "    count(\"*\").alias(\"bowler_balls\")\n",
    ")\n",
    "\n",
    "# Присоединяем фичи\n",
    "df_ext = df.join(batter_stats, on=\"batter\", how=\"left\") \\\n",
    "           .join(bowler_stats, on=\"bowler\", how=\"left\") \\\n",
    "           .withColumn(\"is_powerplay\", (col(\"over\") <= 6).cast(\"int\")) \\\n",
    "           .withColumn(\"is_death\", (col(\"over\") >= 16).cast(\"int\")) \\\n",
    "           .withColumn(\"inning\", col(\"inning\").cast(\"int\"))\n",
    "\n",
    "# Ограничиваем категориальные признаки топ-10 + \"other\"\n",
    "top_batters = df_ext.groupBy(\"batter\").count().orderBy(col(\"count\").desc()).limit(10).select(\"batter\").rdd.flatMap(lambda x: x).collect()\n",
    "top_bowlers = df_ext.groupBy(\"bowler\").count().orderBy(col(\"count\").desc()).limit(10).select(\"bowler\").rdd.flatMap(lambda x: x).collect()\n",
    "df_ext = df_ext.withColumn(\"batter_mod\", when(col(\"batter\").isin(top_batters), col(\"batter\")).otherwise(\"other\"))\n",
    "df_ext = df_ext.withColumn(\"bowler_mod\", when(col(\"bowler\").isin(top_bowlers), col(\"bowler\")).otherwise(\"other\"))\n",
    "\n",
    "# OneHotEncoding\n",
    "batter_indexer = StringIndexer(inputCol=\"batter_mod\", outputCol=\"batter_mod_idx\")\n",
    "bowler_indexer = StringIndexer(inputCol=\"bowler_mod\", outputCol=\"bowler_mod_idx\")\n",
    "batting_team_indexer = StringIndexer(inputCol=\"batting_team\", outputCol=\"batting_team_idx\")\n",
    "bowling_team_indexer = StringIndexer(inputCol=\"bowling_team\", outputCol=\"bowling_team_idx\")\n",
    "\n",
    "batter_encoder = OneHotEncoder(inputCol=\"batter_mod_idx\", outputCol=\"batter_ohe\")\n",
    "bowler_encoder = OneHotEncoder(inputCol=\"bowler_mod_idx\", outputCol=\"bowler_ohe\")\n",
    "batting_team_encoder = OneHotEncoder(inputCol=\"batting_team_idx\", outputCol=\"batting_team_ohe\")\n",
    "bowling_team_encoder = OneHotEncoder(inputCol=\"bowling_team_idx\", outputCol=\"bowling_team_ohe\")\n",
    "\n",
    "# Собираем все фичи\n",
    "features = [\n",
    "    \"over\", \"ball\", \"inning\", \"is_powerplay\", \"is_death\",\n",
    "    \"batter_avg\", \"batter_boundary_pct\", \"bowler_avg\", \"bowler_boundary_pct\",\n",
    "    \"batter_balls\", \"bowler_balls\",\n",
    "    \"batter_ohe\", \"bowler_ohe\", \"batting_team_ohe\", \"bowling_team_ohe\"\n",
    "]\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "\n",
    "# Модель и pipeline\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"total_runs\", numTrees=100, maxDepth=8, seed=42)\n",
    "pipeline = Pipeline(stages=[\n",
    "    batter_indexer, bowler_indexer, batting_team_indexer, bowling_team_indexer,\n",
    "    batter_encoder, bowler_encoder, batting_team_encoder, bowling_team_encoder,\n",
    "    assembler, rf\n",
    "])\n",
    "\n",
    "model = pipeline.fit(df_ext)\n",
    "pred = model.transform(df_ext)\n",
    "\n",
    "rmse = RegressionEvaluator(labelCol=\"total_runs\", predictionCol=\"prediction\", metricName=\"rmse\").evaluate(pred)\n",
    "r2 = RegressionEvaluator(labelCol=\"total_runs\", predictionCol=\"prediction\", metricName=\"r2\").evaluate(pred)\n",
    "print(f\"RandomForestRegressor:\\nRMSE: {rmse:.3f}\\nR2: {r2:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
